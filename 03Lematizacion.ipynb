{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3f3f88",
   "metadata": {},
   "source": [
    "# Lematización real usando NLTK\n",
    "Este notebook aplica lematización real sobre los tokens usando `WordNetLemmatizer` de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea301f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/rodrigovillacinda/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rodrigovillacinda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rodrigovillacinda/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rodrigovillacinda/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, download\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "\n",
    "# Descargar recursos necesarios de NLTK (si no se tienen)\n",
    "download('stopwords')\n",
    "download('wordnet')\n",
    "download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "018e329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función auxiliar para mapear POS tags de NLTK a los de WordNet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9008ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización, limpieza, stopwords y lematización\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lematizar_texto(texto):\n",
    "    tokens = re.findall(r'[a-zA-Z]+', str(texto).lower())\n",
    "    tokens_filtrados = [token for token in tokens if token not in stop_words]\n",
    "    tagged = pos_tag(tokens_filtrados)\n",
    "    lemas = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged]\n",
    "    return lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae16f70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_limpio_limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>[i, d, have, respond, if, i, be, go]</td>\n",
       "      <td>i d have respond if i be go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>[my, bos, be, bully]</td>\n",
       "      <td>my bos be bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>[what, interview, leave, alone]</td>\n",
       "      <td>what interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>[son, of, why, couldn, t, they, put, them, on,...</td>\n",
       "      <td>son of why couldn t they put them on the relea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                I`d have responded, if I were going   \n",
       "1      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                          my boss is bullying me...   \n",
       "3                     what interview! leave me alone   \n",
       "4   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0               [i, d, have, respond, if, i, be, go]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                               [my, bos, be, bully]   \n",
       "3                    [what, interview, leave, alone]   \n",
       "4  [son, of, why, couldn, t, they, put, them, on,...   \n",
       "\n",
       "                                  text_limpio_limpio  \n",
       "0                        i d have respond if i be go  \n",
       "1         sooo sad i will miss you here in san diego  \n",
       "2                                    my bos be bully  \n",
       "3                         what interview leave alone  \n",
       "4  son of why couldn t they put them on the relea...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el dataset limpio\n",
    "df = pd.read_csv(\"01tweetsLimpios.csv\")\n",
    "df[\"tokens\"] = df[\"text\"].apply(lematizar_texto)\n",
    "df[\"text_limpio_limpio\"] = df[\"tokens\"].apply(lambda tokens: \" \".join(tokens))\n",
    "df[[\"text\", \"tokens\", \"text_limpio_limpio\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb334466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Lematización real exportada como 03lemmatized.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_limpio</th>\n",
       "      <th>tokens</th>\n",
       "      <th>text_limpio_limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>[i, d, have, respond, if, i, be, go]</td>\n",
       "      <td>i d have respond if i be go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>[my, bos, be, bully]</td>\n",
       "      <td>my bos be bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>[what, interview, leave, alone]</td>\n",
       "      <td>what interview leave alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>sons of why couldnt they put them on the relea...</td>\n",
       "      <td>[son, of, why, couldn, t, they, put, them, on,...</td>\n",
       "      <td>son of why couldn t they put them on the relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>some shameless plugging for the best rangers f...</td>\n",
       "      <td>[http, www, dothebouncy, com, smf, some, shame...</td>\n",
       "      <td>http www dothebouncy com smf some shameless pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>[be, feeding, for, the, baby, be, fun, when, b...</td>\n",
       "      <td>be feeding for the baby be fun when be all smi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>soooo high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>both of you</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>both of you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>journey wow u just became cooler hehe is that ...</td>\n",
       "      <td>[journey, wow, u, just, become, cool, hehe, be...</td>\n",
       "      <td>journey wow u just become cool hehe be that po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1                                           Sooo SAD  negative   \n",
       "2                                        bullying me  negative   \n",
       "3                                     leave me alone  negative   \n",
       "4                                      Sons of ****,  negative   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral   \n",
       "6                                                fun  positive   \n",
       "7                                         Soooo high   neutral   \n",
       "8                                        Both of you   neutral   \n",
       "9                       Wow... u just became cooler.  positive   \n",
       "\n",
       "                                         text_limpio  \\\n",
       "0                  id have responded if i were going   \n",
       "1         sooo sad i will miss you here in san diego   \n",
       "2                             my boss is bullying me   \n",
       "3                      what interview leave me alone   \n",
       "4  sons of why couldnt they put them on the relea...   \n",
       "5  some shameless plugging for the best rangers f...   \n",
       "6  2am feedings for the baby are fun when he is a...   \n",
       "7                                         soooo high   \n",
       "8                                        both of you   \n",
       "9  journey wow u just became cooler hehe is that ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0               [i, d, have, respond, if, i, be, go]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                               [my, bos, be, bully]   \n",
       "3                    [what, interview, leave, alone]   \n",
       "4  [son, of, why, couldn, t, they, put, them, on,...   \n",
       "5  [http, www, dothebouncy, com, smf, some, shame...   \n",
       "6  [be, feeding, for, the, baby, be, fun, when, b...   \n",
       "7                                      [soooo, high]   \n",
       "8                                    [both, of, you]   \n",
       "9  [journey, wow, u, just, become, cool, hehe, be...   \n",
       "\n",
       "                                  text_limpio_limpio  \n",
       "0                        i d have respond if i be go  \n",
       "1         sooo sad i will miss you here in san diego  \n",
       "2                                    my bos be bully  \n",
       "3                         what interview leave alone  \n",
       "4  son of why couldn t they put them on the relea...  \n",
       "5  http www dothebouncy com smf some shameless pl...  \n",
       "6  be feeding for the baby be fun when be all smi...  \n",
       "7                                         soooo high  \n",
       "8                                        both of you  \n",
       "9  journey wow u just become cool hehe be that po...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el archivo final con lemas\n",
    "df.to_csv(\"03lemmatized.csv\", index=False)\n",
    "print(\"✅ Lematización real exportada como 03lemmatized.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7047f20-135b-49ad-993a-f5d6d3a7bb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
